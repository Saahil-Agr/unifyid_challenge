{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request as request\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import collections\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm explanation\n",
    "1. The main feature extracted from the keystroke data for every entry for every user is the time elapsed to type the given key since the last uncorrected key. So if backspace is used, then the time elapsed in typping the erase char, backspace and the new char are all included in the typing time of the new char. The reason for using this is that it is one of the simplest way of encoding corrections at different chars through the typing time which should have some user specific distribution.\n",
    "2. The next feature used is just the raw count of backspaces typed by the user in every attempt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateFeaturizeData(data, user_id, colnames):\n",
    "    valid_str = 'Be Authentic. Be Yourself. Be Typing.'\n",
    "    feature_length = len(valid_str) + 1 # 1 for number of backspaces.\n",
    "    user_feature_df = pd.DataFrame(columns = colnames)\n",
    "    invalid_count = 0\n",
    "    invalid_idx = []\n",
    "    total_count = len(data)\n",
    "#     if total_count < 300:\n",
    "#         print('insufficient data for user {}'.format(user_id))\n",
    "#         return None, ()\n",
    "    for idx, typed_str in enumerate(data):\n",
    "        processed_str = []\n",
    "        prev_time_stamp = None\n",
    "        backstrokes = 0\n",
    "        user_features = []\n",
    "        for char_dict in typed_str:\n",
    "            curr_char = char_dict[\"character\"]\n",
    "            if curr_char == \"[backspace]\":\n",
    "                processed_str.pop() # remove the last char\n",
    "                user_features.pop() # remove the typing time corresponding to last char\n",
    "                backstrokes += 1\n",
    "            else:\n",
    "                curr_time_stamp = datetime.datetime.strptime(char_dict['typed_at'], '%Y-%m-%dT%H:%M:%S.%f')\n",
    "                if prev_time_stamp:\n",
    "                    typing_time = (curr_time_stamp - prev_time_stamp).total_seconds()\n",
    "                else:\n",
    "                    typing_time = 0.0\n",
    "                processed_str.append(curr_char)\n",
    "                prev_time_stamp = curr_time_stamp\n",
    "                user_features.append(typing_time)       \n",
    "            \n",
    "        \n",
    "        filtered_str = ''.join(processed_str)\n",
    "        if filtered_str == valid_str:\n",
    "            # append it to the dataframe.\n",
    "            user_features.append(backstrokes)\n",
    "            if len(user_features) != feature_length:\n",
    "                print('Mismatch in feature length for a valid string.\\n\\\n",
    "The original string is {}.\\n\\\n",
    "The processed string is {}.\\n\\\n",
    "The number of backspaces are {}.\\n\\\n",
    "User features list is {}'.format(typed_str, processed_str, backstrokes, user_features))\n",
    "            \n",
    "            else:\n",
    "                user_feature_df = user_feature_df.append(pd.Series(user_features, index = colnames), ignore_index = True)\n",
    "        else:\n",
    "#             print('invalid string: '+filtered_str)# do nothing and pass\n",
    "            invalid_count += 1\n",
    "            invalid_idx.append(idx)\n",
    "    \n",
    "    user_feature_df['user_id'] = user_id        \n",
    "#     print(user_feature_df)\n",
    "#     print(user_id, total_count, invalid_count)\n",
    "    return user_feature_df, (total_count, invalid_count), invalid_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Train Data\n",
    "\n",
    "Code to read the input data from the provided urls, filter valid strings and hence enroll eligible users and featurize their typing data and convert it to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = 'https://challenges.unify.id/v1/mle'\n",
    "total_users = 0\n",
    "next_user = 'user_4a438fdede4e11e9b986acde48001122.json'\n",
    "url_error = 0\n",
    "stats = collections.defaultdict(list)\n",
    "unenrolled_users = []\n",
    "no_features = len('Be Authentic. Be Yourself. Be Typing.')\n",
    "col_names = ['f_{}'.format(i) for i in range(1, no_features+1)]\n",
    "col_names += ['del', 'user_id']\n",
    "train_data = pd.DataFrame(columns = col_names)\n",
    "while next_user:\n",
    "    url = os.path.join(domain, next_user)\n",
    "    with request.urlopen(url) as response:\n",
    "            if response.getcode() == 200:\n",
    "                source = response.read()\n",
    "                data = json.loads(source)\n",
    "                total_users += 1\n",
    "                user_df, user_stats, _ = validateFeaturizeData(data['user_data'], next_user, col_names[:-1])\n",
    "                if user_stats[0] - user_stats[1] >= 300:\n",
    "                    stats['user'].append(next_user)\n",
    "                    stats['total_count'].append(user_stats[0])\n",
    "                    stats['invalid_count'].append(user_stats[1])\n",
    "                    train_data = train_data.append(user_df)\n",
    "                else:\n",
    "                    # user cannot be enrolled into production due to threshold.\n",
    "                    unenrolled_users.append(next_user)\n",
    "                \n",
    "                next_user = data['next']\n",
    "            else:\n",
    "                print('An error occurred while attempting to retrieve data from the API. Invalid User hash {}'.format(next_user))\n",
    "                url_error += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enrolled users are \n",
      "['user_4a438fdede4e11e9b986acde48001122.json', 'user_4a45245cde4e11e9b51bacde48001122.json', 'user_4a4558dcde4e11e9bbfaacde48001122.json', 'user_4a45bafade4e11e99e37acde48001122.json', 'user_4a45f03ade4e11e9922cacde48001122.json', 'user_4a4626c2de4e11e98c17acde48001122.json', 'user_4a466e5cde4e11e98e06acde48001122.json', 'user_4a46a7a8de4e11e99efeacde48001122.json', 'user_4a46debede4e11e996d6acde48001122.json', 'user_4a47153ade4e11e9a04eacde48001122.json', 'user_4a474bf6de4e11e980dbacde48001122.json', 'user_4a47885ade4e11e98c41acde48001122.json', 'user_4a482be8de4e11e9a2a2acde48001122.json', 'user_4a486266de4e11e98893acde48001122.json', 'user_4a4898e4de4e11e98573acde48001122.json', 'user_4a4905d8de4e11e99a50acde48001122.json', 'user_4a493c4ade4e11e99e33acde48001122.json', 'user_4a497764de4e11e9bc80acde48001122.json', 'user_4a49ae0ade4e11e9b2d3acde48001122.json', 'user_4a49e492de4e11e98206acde48001122.json', 'user_4a4a1b1ade4e11e9a868acde48001122.json', 'user_4a4a518cde4e11e99ae3acde48001122.json', 'user_4a4a8802de4e11e9a447acde48001122.json', 'user_4a4abe80de4e11e9963bacde48001122.json', 'user_4a4af4fede4e11e9b4c8acde48001122.json', 'user_4a4b2b86de4e11e99e25acde48001122.json', 'user_4a4b6358de4e11e9b361acde48001122.json', 'user_4a4b99d8de4e11e9ab53acde48001122.json', 'user_4a4bd05ede4e11e987bfacde48001122.json', 'user_4a4c06f0de4e11e997dfacde48001122.json', 'user_4a4c3d6ede4e11e98e3bacde48001122.json', 'user_4a4c73e2de4e11e98b63acde48001122.json', 'user_4a4ce17ede4e11e9a181acde48001122.json', 'user_4a4d17f4de4e11e9bdbaacde48001122.json', 'user_4a4d4e70de4e11e9a835acde48001122.json']\n",
      "\n",
      "Unenrolled users are \n",
      "['user_4a4587d0de4e11e9857aacde48001122.json', 'user_4a47beecde4e11e9aea4acde48001122.json', 'user_4a47f568de4e11e98afcacde48001122.json', 'user_4a48cf62de4e11e9a654acde48001122.json', 'user_4a4cab0ade4e11e99c31acde48001122.json']\n"
     ]
    }
   ],
   "source": [
    "# List of enrolled and unenrolled Users\n",
    "print('Enrolled users are \\n{}'.format(stats['user']))\n",
    "print('\\nUnenrolled users are \\n{}'.format(unenrolled_users))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture and Training\n",
    "The model used here is a simple feed forward 3 layer neural network. The final layer of the model is a softmax that outputs the probability distribution over all the enrolled users.\n",
    "While more complex models like LSTM are better suited for the task, this model forms an appropriate baseline since it is one of the most simple architecture with basic feature extraction and engineering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "# from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.utils import shuffle\n",
    "from keras import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               3800      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 35)                1785      \n",
      "=================================================================\n",
      "Total params: 10,635\n",
      "Trainable params: 10,635\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 3.5481 - accuracy: 0.0590 - val_loss: 3.5253 - val_accuracy: 0.1098\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.5231 - accuracy: 0.0803 - val_loss: 3.4997 - val_accuracy: 0.1127\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.4976 - accuracy: 0.0913 - val_loss: 3.4637 - val_accuracy: 0.0836\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.4567 - accuracy: 0.0913 - val_loss: 3.4069 - val_accuracy: 0.0906\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.3902 - accuracy: 0.0802 - val_loss: 3.3225 - val_accuracy: 0.0987\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.2947 - accuracy: 0.1002 - val_loss: 3.2103 - val_accuracy: 0.1312\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.1716 - accuracy: 0.1158 - val_loss: 3.0758 - val_accuracy: 0.1533\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.0279 - accuracy: 0.1204 - val_loss: 2.9297 - val_accuracy: 0.1272\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.8889 - accuracy: 0.1304 - val_loss: 2.8051 - val_accuracy: 0.1504\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2.7666 - accuracy: 0.1656 - val_loss: 2.6975 - val_accuracy: 0.1812\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.6605 - accuracy: 0.1755 - val_loss: 2.6004 - val_accuracy: 0.1835\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.5654 - accuracy: 0.2038 - val_loss: 2.5162 - val_accuracy: 0.2247\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.4793 - accuracy: 0.2467 - val_loss: 2.4395 - val_accuracy: 0.2387\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.4030 - accuracy: 0.2378 - val_loss: 2.3695 - val_accuracy: 0.2549\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.3339 - accuracy: 0.2502 - val_loss: 2.3101 - val_accuracy: 0.2532\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.2709 - accuracy: 0.2685 - val_loss: 2.2486 - val_accuracy: 0.2933\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.2121 - accuracy: 0.3011 - val_loss: 2.2030 - val_accuracy: 0.2741\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.1585 - accuracy: 0.3008 - val_loss: 2.1484 - val_accuracy: 0.2909\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.1112 - accuracy: 0.2964 - val_loss: 2.0994 - val_accuracy: 0.3333\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.0644 - accuracy: 0.3242 - val_loss: 2.0615 - val_accuracy: 0.3078\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.0204 - accuracy: 0.3205 - val_loss: 2.0191 - val_accuracy: 0.3420\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.9792 - accuracy: 0.3465 - val_loss: 1.9709 - val_accuracy: 0.3693\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.9401 - accuracy: 0.3627 - val_loss: 1.9411 - val_accuracy: 0.3670\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.9053 - accuracy: 0.3591 - val_loss: 1.9081 - val_accuracy: 0.3502\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.8722 - accuracy: 0.3786 - val_loss: 1.8797 - val_accuracy: 0.4048\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.8416 - accuracy: 0.3922 - val_loss: 1.8413 - val_accuracy: 0.3746\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.8084 - accuracy: 0.4003 - val_loss: 1.8215 - val_accuracy: 0.3908\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.7815 - accuracy: 0.3959 - val_loss: 1.7883 - val_accuracy: 0.4100\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.7559 - accuracy: 0.4048 - val_loss: 1.7667 - val_accuracy: 0.4239\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.7313 - accuracy: 0.4169 - val_loss: 1.7434 - val_accuracy: 0.4199\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.7094 - accuracy: 0.4210 - val_loss: 1.7161 - val_accuracy: 0.4373\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.6889 - accuracy: 0.4212 - val_loss: 1.7046 - val_accuracy: 0.4524\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.6682 - accuracy: 0.4294 - val_loss: 1.6804 - val_accuracy: 0.4355\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.6511 - accuracy: 0.4281 - val_loss: 1.6564 - val_accuracy: 0.4367\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.6320 - accuracy: 0.4392 - val_loss: 1.6484 - val_accuracy: 0.4257\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.6168 - accuracy: 0.4342 - val_loss: 1.6204 - val_accuracy: 0.4448\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.5970 - accuracy: 0.4467 - val_loss: 1.6045 - val_accuracy: 0.4628\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.5825 - accuracy: 0.4437 - val_loss: 1.5923 - val_accuracy: 0.4547\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.5687 - accuracy: 0.4561 - val_loss: 1.5858 - val_accuracy: 0.4570\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.5575 - accuracy: 0.4545 - val_loss: 1.5647 - val_accuracy: 0.4750\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.5442 - accuracy: 0.4551 - val_loss: 1.5465 - val_accuracy: 0.4640\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.5287 - accuracy: 0.4643 - val_loss: 1.5356 - val_accuracy: 0.4797\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.5172 - accuracy: 0.4681 - val_loss: 1.5275 - val_accuracy: 0.4437\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.5083 - accuracy: 0.4704 - val_loss: 1.5256 - val_accuracy: 0.4739\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.5001 - accuracy: 0.4690 - val_loss: 1.5114 - val_accuracy: 0.4791\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.4880 - accuracy: 0.4661 - val_loss: 1.5002 - val_accuracy: 0.4710\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.4782 - accuracy: 0.4702 - val_loss: 1.4867 - val_accuracy: 0.4762\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.4680 - accuracy: 0.4710 - val_loss: 1.4779 - val_accuracy: 0.4634\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.4577 - accuracy: 0.4689 - val_loss: 1.4693 - val_accuracy: 0.4756\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.4514 - accuracy: 0.4720 - val_loss: 1.4731 - val_accuracy: 0.4895\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.4438 - accuracy: 0.4854 - val_loss: 1.4511 - val_accuracy: 0.4948\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.4353 - accuracy: 0.4767 - val_loss: 1.4463 - val_accuracy: 0.5017\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 1.4280 - accuracy: 0.4785 - val_loss: 1.4367 - val_accuracy: 0.5023\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.4230 - accuracy: 0.4818 - val_loss: 1.4378 - val_accuracy: 0.4814\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.4109 - accuracy: 0.4869 - val_loss: 1.4281 - val_accuracy: 0.5093\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.4068 - accuracy: 0.4856 - val_loss: 1.4195 - val_accuracy: 0.4820\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.3999 - accuracy: 0.4904 - val_loss: 1.4144 - val_accuracy: 0.4890\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.3957 - accuracy: 0.4902 - val_loss: 1.4122 - val_accuracy: 0.5017\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.3899 - accuracy: 0.4876 - val_loss: 1.4053 - val_accuracy: 0.5105\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.3861 - accuracy: 0.4920 - val_loss: 1.3930 - val_accuracy: 0.4797\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.3751 - accuracy: 0.4920 - val_loss: 1.3929 - val_accuracy: 0.4884\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.3714 - accuracy: 0.4940 - val_loss: 1.3793 - val_accuracy: 0.4977\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.3652 - accuracy: 0.4932 - val_loss: 1.3849 - val_accuracy: 0.4954\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.3599 - accuracy: 0.4931 - val_loss: 1.3779 - val_accuracy: 0.4936\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.3566 - accuracy: 0.4952 - val_loss: 1.3687 - val_accuracy: 0.4919\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.3504 - accuracy: 0.5028 - val_loss: 1.3704 - val_accuracy: 0.5116\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.3432 - accuracy: 0.5029 - val_loss: 1.3573 - val_accuracy: 0.5134\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.3450 - accuracy: 0.5025 - val_loss: 1.3484 - val_accuracy: 0.5087\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.3387 - accuracy: 0.4945 - val_loss: 1.3519 - val_accuracy: 0.5087\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.3336 - accuracy: 0.4995 - val_loss: 1.3432 - val_accuracy: 0.5209\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.3307 - accuracy: 0.4953 - val_loss: 1.3405 - val_accuracy: 0.5244\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.3268 - accuracy: 0.5025 - val_loss: 1.3431 - val_accuracy: 0.5006\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.3218 - accuracy: 0.5049 - val_loss: 1.3351 - val_accuracy: 0.5128\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.3179 - accuracy: 0.5062 - val_loss: 1.3327 - val_accuracy: 0.5157\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.3171 - accuracy: 0.5131 - val_loss: 1.3340 - val_accuracy: 0.5128\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.3166 - accuracy: 0.5081 - val_loss: 1.3257 - val_accuracy: 0.4919\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.3092 - accuracy: 0.5055 - val_loss: 1.3217 - val_accuracy: 0.5308\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.3065 - accuracy: 0.5129 - val_loss: 1.3269 - val_accuracy: 0.5087\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.3013 - accuracy: 0.5170 - val_loss: 1.3184 - val_accuracy: 0.5023\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.3011 - accuracy: 0.5129 - val_loss: 1.3091 - val_accuracy: 0.5174\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.2953 - accuracy: 0.5093 - val_loss: 1.3130 - val_accuracy: 0.5343\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.2946 - accuracy: 0.5118 - val_loss: 1.3012 - val_accuracy: 0.5337\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.2909 - accuracy: 0.5145 - val_loss: 1.2995 - val_accuracy: 0.5267\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.2905 - accuracy: 0.5136 - val_loss: 1.3058 - val_accuracy: 0.5279\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.2842 - accuracy: 0.5188 - val_loss: 1.3059 - val_accuracy: 0.5099\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.2813 - accuracy: 0.5205 - val_loss: 1.2944 - val_accuracy: 0.5273\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.2774 - accuracy: 0.5158 - val_loss: 1.2989 - val_accuracy: 0.5244\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.2761 - accuracy: 0.5159 - val_loss: 1.3034 - val_accuracy: 0.5157\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.2737 - accuracy: 0.5185 - val_loss: 1.2821 - val_accuracy: 0.5226\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.2721 - accuracy: 0.5178 - val_loss: 1.2894 - val_accuracy: 0.5331\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.2722 - accuracy: 0.5276 - val_loss: 1.2819 - val_accuracy: 0.5238\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.2689 - accuracy: 0.5207 - val_loss: 1.2747 - val_accuracy: 0.5273\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.2663 - accuracy: 0.5190 - val_loss: 1.2785 - val_accuracy: 0.5360\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.2671 - accuracy: 0.5205 - val_loss: 1.2850 - val_accuracy: 0.5180\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.2608 - accuracy: 0.5235 - val_loss: 1.2757 - val_accuracy: 0.5267\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.2610 - accuracy: 0.5183 - val_loss: 1.2778 - val_accuracy: 0.5273\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.2576 - accuracy: 0.5218 - val_loss: 1.2727 - val_accuracy: 0.5180\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.2522 - accuracy: 0.5255 - val_loss: 1.2668 - val_accuracy: 0.5436\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.2522 - accuracy: 0.5218 - val_loss: 1.2615 - val_accuracy: 0.5407\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.2527 - accuracy: 0.5246 - val_loss: 1.2580 - val_accuracy: 0.5319\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1447f3780>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_classes = int(train_data.user_id.nunique())\n",
    "train_data = shuffle(train_data)\n",
    "X_train = train_data.iloc[:,1:-1]\n",
    "Y_train = train_data.iloc[:,-1]\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y_train)\n",
    "encoded_Y = encoder.transform(Y_train)\n",
    "mapping = dict(zip(range(len(encoder.classes_)), encoder.classes_))\n",
    "mapping[-1] = 'invalid input'\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)\n",
    " \n",
    "# define baseline model\n",
    "def baseline_model(input_dims, hidden_units, no_classes):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_units[0], input_dim=input_dims, activation='relu'))\n",
    "    model.add(Dense(hidden_units[1], activation='relu'))\n",
    "    model.add(Dense(no_classes, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = baseline_model(no_features, [100, 50], no_classes)\n",
    "print(model.summary())\n",
    "checkpoint_filepath = os.path.join(os.getcwd(), 'model_checkpoint/')\n",
    "model_checkpoint_callback = callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "model.fit(X_train, dummy_y, epochs=100, batch_size=1024, validation_split=0.1, callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    35.000000\n",
       "mean      0.498214\n",
       "std       0.265494\n",
       "min       0.012698\n",
       "25%       0.309797\n",
       "50%       0.544554\n",
       "75%       0.708637\n",
       "max       0.952978\n",
       "Name: acc, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# User performance report\n",
    "model.load_weights(checkpoint_filepath)\n",
    "train_pred_class = np.argmax(model.predict(X_train), axis=-1)\n",
    "perf_df = pd.DataFrame({'y_true' : encoded_Y, 'y_pred': train_pred_class})\n",
    "perf_df['outcome'] = perf_df.y_true == perf_df.y_pred\n",
    "perf_df = perf_df.groupby('y_true')['outcome'].agg(['sum', 'count'])\n",
    "perf_df.reset_index(inplace = True)\n",
    "perf_df['acc'] = perf_df['sum']/perf_df['count']\n",
    "perf_df.to_csv(os.path.join(os.getcwd(),'user_level_perf.csv'), header = True, index=False)\n",
    "perf_df.acc.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Data\n",
    "test_url = 'https://challenges.unify.id/v1/mle/sample_test.json'\n",
    "with request.urlopen(test_url) as response:\n",
    "    if response.getcode() == 200:\n",
    "        source = response.read()\n",
    "        data = json.loads(source)\n",
    "        test_df, user_stats, invalid_idx = validateFeaturizeData(data['attempts'], 'test', col_names[:-1])\n",
    "\n",
    "final_idx = []\n",
    "for i, idx in enumerate(invalid_idx):\n",
    "    final_idx.append(idx-i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting for the test data\n",
    "X_test = test_df.iloc[:,1:-1]\n",
    "# pred_class = model.predict_classes(X_test)\n",
    "pred_class = np.argmax(model.predict(X_test), axis=-1)\n",
    "# print(pred_class.shape)\n",
    "pred_class = np.insert(pred_class, final_idx , -1)\n",
    "pred_user = []\n",
    "for user in pred_class:\n",
    "    pred_user.append(mapping[user])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('final_pred.json', 'w') as fp:\n",
    "    json.dump(pred_user, fp)\n",
    "# json.dumps(pred_user)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
